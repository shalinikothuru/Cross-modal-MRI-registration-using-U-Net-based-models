{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-12-10 16:56:14.306313: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 16:56:14.325871: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 16:56:14.325888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 16:56:14.326419: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 16:56:14.329878: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 16:56:14.698764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import dipy\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "from dipy.viz import regtools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCP_folder = '/Users/sreekar/mounts/GRG/data/HCP/'\n",
    "HCP_folder = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PA', 'T1', '.DS_Store', 'AP']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(HCP_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "T1_file = HCP_folder + \"/T1/102109.nii.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1, T1_affine = dipy.io.image.load_nifti(T1_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutualInformation(bin_centers,\n",
    "                      sigma_ratio=0.5,    # sigma for soft MI. If not provided, it will be half of a bin length\n",
    "                      max_clip=1,\n",
    "                      crop_background=False, # crop_background should never be true if local_mi is True\n",
    "                      local_mi=False,\n",
    "                      patch_size=1):\n",
    "    \"\"\"\n",
    "    mutual information for image-image pairs.\n",
    "    Author: Courtney Guo. See thesis https://dspace.mit.edu/handle/1721.1/123142\n",
    "    \"\"\"\n",
    "    # print(\"vxm:mutual information loss is experimental.\", file=sts.stderr)\n",
    "    \n",
    "    if local_mi:\n",
    "        return localMutualInformation(bin_centers, vol_size=(128, 128, 128), sigma_ratio=sigma_ratio, max_clip=max_clip, patch_size=patch_size)\n",
    "\n",
    "    else:\n",
    "        return globalMutualInformation(bin_centers, sigma_ratio, max_clip, crop_background)\n",
    "\n",
    "\n",
    "def localMutualInformation(bin_centers,\n",
    "                      vol_size=(128, 128, 128),\n",
    "                      sigma_ratio=0.5,\n",
    "                      max_clip=1,\n",
    "                      patch_size=1):\n",
    "    \"\"\"\n",
    "    Local Mutual Information for image-image pairs\n",
    "    # vol_size is something like (160, 192, 224)  \n",
    "    This function assumes that y_true and y_pred are both (batch_sizexheightxwidthxdepthxchan)\n",
    "    Author: Courtney Guo. See thesis at https://dspace.mit.edu/handle/1721.1/123142\n",
    "    \"\"\"\n",
    "    # print(\"vxm:mutual information loss is experimental.\", file=sts.stderr)\n",
    "\n",
    "    \"\"\" prepare MI. \"\"\"\n",
    "    vol_bin_centers = K.variable(bin_centers)\n",
    "    num_bins = len(bin_centers)\n",
    "    sigma = np.mean(np.diff(bin_centers))*sigma_ratio\n",
    "\n",
    "    preterm = K.variable(1 / (2 * np.square(sigma)))\n",
    "\n",
    "    def local_mi(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, 0, max_clip)\n",
    "        y_true = K.clip(y_true, 0, max_clip)\n",
    "\n",
    "        # reshape bin centers to be (1, 1, B)\n",
    "        o = [1, 1, 1, 1, num_bins]\n",
    "        vbc = K.reshape(vol_bin_centers, o)\n",
    "        \n",
    "        # compute padding sizes\n",
    "        x, y, z = vol_size\n",
    "        x_r = -x % patch_size\n",
    "        y_r = -y % patch_size\n",
    "        z_r = -z % patch_size\n",
    "        pad_dims = [[0,0]]\n",
    "        pad_dims.append([x_r//2, x_r - x_r//2])\n",
    "        pad_dims.append([y_r//2, y_r - y_r//2])\n",
    "        pad_dims.append([z_r//2, z_r - z_r//2])\n",
    "        pad_dims.append([0,0])\n",
    "        padding = tf.constant(pad_dims)\n",
    "\n",
    "        # compute image terms\n",
    "        # num channels of y_true and y_pred must be 1\n",
    "        I_a = K.exp(- preterm * K.square(tf.pad(y_true, padding, 'CONSTANT')  - vbc))\n",
    "        I_a /= K.sum(I_a, -1, keepdims=True)\n",
    "\n",
    "        I_b = K.exp(- preterm * K.square(tf.pad(y_pred, padding, 'CONSTANT')  - vbc))\n",
    "        I_b /= K.sum(I_b, -1, keepdims=True)\n",
    "\n",
    "        I_a_patch = tf.reshape(I_a, [(x+x_r)//patch_size, patch_size, (y+y_r)//patch_size, patch_size, (z+z_r)//patch_size, patch_size, num_bins])\n",
    "        I_a_patch = tf.transpose(I_a_patch, [0, 2, 4, 1, 3, 5, 6])\n",
    "        I_a_patch = tf.reshape(I_a_patch, [-1, patch_size**3, num_bins])\n",
    "\n",
    "        I_b_patch = tf.reshape(I_b, [(x+x_r)//patch_size, patch_size, (y+y_r)//patch_size, patch_size, (z+z_r)//patch_size, patch_size, num_bins])\n",
    "        I_b_patch = tf.transpose(I_b_patch, [0, 2, 4, 1, 3, 5, 6])\n",
    "        I_b_patch = tf.reshape(I_b_patch, [-1, patch_size**3, num_bins])\n",
    "\n",
    "        # compute probabilities\n",
    "        I_a_permute = K.permute_dimensions(I_a_patch, (0,2,1))\n",
    "        pab = K.batch_dot(I_a_permute, I_b_patch)  # should be the right size now, nb_labels x nb_bins\n",
    "        pab /= patch_size**3\n",
    "        pa = tf.reduce_mean(I_a_patch, 1, keepdims=True)\n",
    "        pb = tf.reduce_mean(I_b_patch, 1, keepdims=True)\n",
    "        \n",
    "        papb = K.batch_dot(K.permute_dimensions(pa, (0,2,1)), pb) + K.epsilon()\n",
    "        mi = K.mean(K.sum(K.sum(pab * K.log(pab/papb + K.epsilon()), 1), 1))\n",
    "\n",
    "        return mi\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        return -local_mi(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def globalMutualInformation(bin_centers,\n",
    "                      sigma_ratio=0.5,\n",
    "                      max_clip=1,\n",
    "                      crop_background=False):\n",
    "    \"\"\"\n",
    "    Mutual Information for image-image pairs\n",
    "    Building from neuron.losses.MutualInformationSegmentation()    \n",
    "    This function assumes that y_true and y_pred are both (batch_size x height x width x depth x nb_chanels)\n",
    "    Author: Courtney Guo. See thesis at https://dspace.mit.edu/handle/1721.1/123142\n",
    "    \"\"\"\n",
    "    # print(\"vxm:mutual information loss is experimental.\", file=sts.stderr)\n",
    "\n",
    "    \"\"\" prepare MI. \"\"\"\n",
    "    vol_bin_centers = K.variable(bin_centers)\n",
    "    num_bins = len(bin_centers)\n",
    "    sigma = np.mean(np.diff(bin_centers))*sigma_ratio\n",
    "\n",
    "    preterm = K.variable(1 / (2 * np.square(sigma)))\n",
    "\n",
    "    def mi(y_true, y_pred):\n",
    "        \"\"\" soft mutual info \"\"\"\n",
    "        y_pred = K.clip(y_pred, 0, max_clip)\n",
    "        y_true = K.clip(y_true, 0, max_clip)\n",
    "\n",
    "        if crop_background:\n",
    "            # does not support variable batch size\n",
    "            thresh = 0.0001\n",
    "            padding_size = 20\n",
    "            filt = tf.ones([padding_size, padding_size, padding_size, 1, 1])\n",
    "\n",
    "            smooth = tf.nn.conv3d(y_true, filt, [1, 1, 1, 1, 1], \"SAME\")\n",
    "            mask = smooth > thresh\n",
    "            # mask = K.any(K.stack([y_true > thresh, y_pred > thresh], axis=0), axis=0)\n",
    "            y_pred = tf.boolean_mask(y_pred, mask)\n",
    "            y_true = tf.boolean_mask(y_true, mask)\n",
    "            y_pred = K.expand_dims(K.expand_dims(y_pred, 0), 2)\n",
    "            y_true = K.expand_dims(K.expand_dims(y_true, 0), 2)\n",
    "\n",
    "        else:\n",
    "            # reshape: flatten images into shape (batch_size, heightxwidthxdepthxchan, 1)\n",
    "            y_true = K.reshape(y_true, (-1, K.prod(K.shape(y_true)[1:])))\n",
    "            y_true = K.expand_dims(y_true, 2)\n",
    "            y_pred = K.reshape(y_pred, (-1, K.prod(K.shape(y_pred)[1:])))\n",
    "            y_pred = K.expand_dims(y_pred, 2)\n",
    "        \n",
    "        nb_voxels = tf.cast(K.shape(y_pred)[1], tf.float32)\n",
    "\n",
    "        # reshape bin centers to be (1, 1, B)\n",
    "        o = [1, 1, np.prod(vol_bin_centers.get_shape().as_list())]\n",
    "        vbc = K.reshape(vol_bin_centers, o)\n",
    "        \n",
    "        # compute image terms\n",
    "        I_a = K.exp(- preterm * K.square(y_true  - vbc))\n",
    "        I_a /= K.sum(I_a, -1, keepdims=True)\n",
    "\n",
    "        I_b = K.exp(- preterm * K.square(y_pred  - vbc))\n",
    "        I_b /= K.sum(I_b, -1, keepdims=True)\n",
    "\n",
    "        # compute probabilities\n",
    "        I_a_permute = K.permute_dimensions(I_a, (0,2,1))\n",
    "        pab = K.batch_dot(I_a_permute, I_b)  # should be the right size now, nb_labels x nb_bins\n",
    "        pab /= nb_voxels\n",
    "        pa = tf.reduce_mean(I_a, 1, keepdims=True)\n",
    "        pb = tf.reduce_mean(I_b, 1, keepdims=True)\n",
    "        \n",
    "        papb = K.batch_dot(K.permute_dimensions(pa, (0,2,1)), pb) + K.epsilon()\n",
    "        mi = K.sum(K.sum(pab * K.log(pab/papb + K.epsilon()), 1), 1)\n",
    "\n",
    "        return mi\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        return -mi(y_true, y_pred)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_loss(phi, norm=2):\n",
    "    di = tf.abs(phi[:, 1:, :, :, :] - phi[:, :-1, :, :, :])\n",
    "    dj = tf.abs(phi[:, :, 1:, :, :] - phi[:, :, :-1, :, :])\n",
    "    dk = tf.abs(phi[:, :, :, 1:, :] - phi[:, :, :, :-1, :])\n",
    "\n",
    "    loss = tf.reduce_mean(di) + tf.reduce_mean(dj) + tf.reduce_mean(dk)\n",
    "    if norm == 2:\n",
    "        loss = tf.reduce_mean(di**2) + tf.reduce_mean(dj**2) + tf.reduce_mean(dk**2)    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_grid_3d(depth, height, width):\n",
    "    i = tf.linspace(-1.0, 1.0, depth)\n",
    "    j = tf.linspace(-1.0, 1.0, height)\n",
    "    k = tf.linspace(-1.0, 1.0, width)\n",
    "\n",
    "    I, J, K = tf.meshgrid(i, j, k, indexing='ij')\n",
    "\n",
    "    grid = tf.stack([I, J, K], axis=-1)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_sample_3d(moving, grid):\n",
    "    nb, nd, nh, nw, nc = tf.shape(moving)\n",
    "\n",
    "    i = grid[..., 0]  # shape (N, D, H, W)\n",
    "    j = grid[..., 1]\n",
    "    k = grid[..., 2]\n",
    "    i = tf.cast(i, 'float32')\n",
    "    j = tf.cast(j, 'float32')\n",
    "    k = tf.cast(k, 'float32')\n",
    "\n",
    "    # Scale i, j and k from [-1.0, 1.0] to [0, D], [0, H] and [0, W] respectively.\n",
    "    i = (i + 1.0) * 0.5 * tf.cast(nd-1, 'float32')\n",
    "    j = (j + 1.0) * 0.5 * tf.cast(nh-1, 'float32')\n",
    "    k = (k + 1.0) * 0.5 * tf.cast(nw-1, 'float32')\n",
    "\n",
    "    i_max = tf.cast(nd - 1, 'int32')\n",
    "    j_max = tf.cast(nh - 1, 'int32')\n",
    "    k_max = tf.cast(nw - 1, 'int32')\n",
    "    zero = tf.constant(0, 'int32')\n",
    "\n",
    "    # The value at (i, j, k) is a weighted average of the values at the\n",
    "    # eight nearest integer locations: (i0, j0, k0), (i0, j0, k1), (i0, j1, k0),\n",
    "    # (i0, j1, k1), (i1, j0, k0), (i1, j0, k1), (i1, j1, k0) and (i1, j1, k1)\n",
    "    # where i0 = floor(i), i1 = ceil(i).\n",
    "    i0 = tf.cast(tf.floor(i), 'int32')\n",
    "    i1 = i0 + 1\n",
    "    j0 = tf.cast(tf.floor(j), 'int32')\n",
    "    j1 = j0 + 1\n",
    "    k0 = tf.cast(tf.floor(k), 'int32')\n",
    "    k1 = k0 + 1\n",
    "\n",
    "    # Make sure indices are within the boundaries of the image.\n",
    "    i0 = tf.clip_by_value(i0, zero, i_max)\n",
    "    i1 = tf.clip_by_value(i1, zero, i_max)\n",
    "    j0 = tf.clip_by_value(j0, zero, j_max)\n",
    "    j1 = tf.clip_by_value(j1, zero, j_max)\n",
    "    k0 = tf.clip_by_value(k0, zero, k_max)\n",
    "    k1 = tf.clip_by_value(k1, zero, k_max)\n",
    "\n",
    "    # Collect indices of the four corners.\n",
    "    b = tf.ones_like(i0) * tf.reshape(tf.range(nb), [nb, 1, 1, 1])\n",
    "    idx_a = tf.stack([b, i1, j0, k0], axis=-1)  # all front-top-left corners\n",
    "    idx_b = tf.stack([b, i1, j1, k0], axis=-1)  # all front-bottom-left corners\n",
    "    idx_c = tf.stack([b, i1, j0, k1], axis=-1)  # all front-top-right corners\n",
    "    idx_d = tf.stack([b, i1, j1, k1], axis=-1)  # all front-bottom-right corners\n",
    "    idx_e = tf.stack([b, i0, j0, k0], axis=-1)  # all back-top-left corners\n",
    "    idx_f = tf.stack([b, i0, j1, k0], axis=-1)  # all back-bottom-left corners\n",
    "    idx_g = tf.stack([b, i0, j0, k1], axis=-1)  # all back-top-right corners\n",
    "    idx_h = tf.stack([b, i0, j1, k1], axis=-1)  # all back-bottom-right corners\n",
    "    # shape (N, D, H, W, 3)\n",
    "\n",
    "    # Collect values at the corners.\n",
    "    moving_a = tf.gather_nd(moving, idx_a)  # all front-top-left values\n",
    "    moving_b = tf.gather_nd(moving, idx_b)  # all front-bottom-left values\n",
    "    moving_c = tf.gather_nd(moving, idx_c)  # all front-top-right values\n",
    "    moving_d = tf.gather_nd(moving, idx_d)  # all front-bottom-right values\n",
    "    moving_e = tf.gather_nd(moving, idx_e)  # all back-top-left values\n",
    "    moving_f = tf.gather_nd(moving, idx_f)  # all back-bottom-left values\n",
    "    moving_g = tf.gather_nd(moving, idx_g)  # all back-top-right values\n",
    "    moving_h = tf.gather_nd(moving, idx_h)  # all back-bottom-right values\n",
    "    # shape (N, D, H, W, C)\n",
    "\n",
    "    i0_f = tf.cast(i0, 'float32')\n",
    "    i1_f = tf.cast(i1, 'float32')\n",
    "    j0_f = tf.cast(j0, 'float32')\n",
    "    j1_f = tf.cast(j1, 'float32')\n",
    "    k0_f = tf.cast(k0, 'float32')\n",
    "    k1_f = tf.cast(k1, 'float32')\n",
    "\n",
    "    # Calculate the weights.\n",
    "    wa = tf.expand_dims((i - i0_f) * (j1_f - j) * (k1_f - k), axis=-1)\n",
    "    wb = tf.expand_dims((i - i0_f) * (j - j0_f) * (k1_f - k), axis=-1)\n",
    "    wc = tf.expand_dims((i - i0_f) * (j1_f - j) * (k - k0_f), axis=-1)\n",
    "    wd = tf.expand_dims((i - i0_f) * (j - j0_f) * (k - k0_f), axis=-1)\n",
    "    we = tf.expand_dims((i1_f - i) * (j1_f - j) * (k1_f - k), axis=-1)\n",
    "    wf = tf.expand_dims((i1_f - i) * (j - j0_f) * (k1_f - k), axis=-1)\n",
    "    wg = tf.expand_dims((i1_f - i) * (j1_f - j) * (k - k0_f), axis=-1)\n",
    "    wh = tf.expand_dims((i1_f - i) * (j - j0_f) * (k - k0_f), axis=-1)\n",
    "\n",
    "    # Calculate the weighted sum.\n",
    "    moved = tf.add_n([wa * moving_a, wb * moving_b, wc * moving_c,\n",
    "                      wd * moving_d, we * moving_e, wf * moving_f,\n",
    "                      wg * moving_g, wh * moving_h])\n",
    "    return moved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelmorph1(input_shape=(320, 320, 1)):\n",
    "    in_channels = 1\n",
    "    out_channels = 3\n",
    "    input_shape = input_shape + (in_channels,)\n",
    "    moving = layers.Input(shape=input_shape, name='moving')\n",
    "    static = layers.Input(shape=input_shape, name='static')\n",
    "    x_in = layers.concatenate([static, moving], axis=-1)\n",
    "\n",
    "    # encoder\n",
    "    x1 = layers.Conv3D(16, kernel_size=3, strides=2, padding='same',\n",
    "                        kernel_initializer='he_normal')(x_in)\n",
    "    x1 = layers.LeakyReLU(alpha=0.2)(x1)  # 16\n",
    "\n",
    "    x2 = layers.Conv3D(32, kernel_size=3, strides=2, padding='same',\n",
    "                        kernel_initializer='he_normal')(x1)\n",
    "    x2 = layers.LeakyReLU(alpha=0.2)(x2)  # 8\n",
    "\n",
    "    x3 = layers.Conv3D(32, kernel_size=3, strides=2, padding='same',\n",
    "                        kernel_initializer='he_normal')(x2)\n",
    "    x3 = layers.LeakyReLU(alpha=0.2)(x3)  # 4\n",
    "\n",
    "    x4 = layers.Conv3D(32, kernel_size=3, strides=2, padding='same',\n",
    "                        kernel_initializer='he_normal')(x3)\n",
    "    x4 = layers.LeakyReLU(alpha=0.2)(x4)  # 2\n",
    "\n",
    "    # decoder [32, 32, 32, 32, 8, 8]\n",
    "    x = layers.Conv3D(32, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x4)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.UpSampling3D(size=2)(x)  # 4\n",
    "    x = layers.concatenate([x, x3], axis=-1)  # 4\n",
    "\n",
    "    x = layers.Conv3D(32, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.UpSampling3D(size=2)(x)  # 8\n",
    "    x = layers.concatenate([x, x2], axis=-1)  # 8\n",
    "\n",
    "    x = layers.Conv3D(32, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "    x = layers.UpSampling3D(size=2)(x)  # 16\n",
    "    x = layers.concatenate([x, x1], axis=-1)  # 16\n",
    "\n",
    "    x = layers.Conv3D(32, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = layers.Conv3D(8, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)  # 16\n",
    "\n",
    "    x = layers.UpSampling3D(size=2)(x)  # 32\n",
    "    x = layers.concatenate([x, x_in], axis=-1)\n",
    "    x = layers.Conv3D(8, kernel_size=3, strides=1, padding='same',\n",
    "                      kernel_initializer='he_normal')(x)\n",
    "    x = layers.LeakyReLU(alpha=0.2)(x)  # 32\n",
    "\n",
    "    kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0,\n",
    "                                                            stddev=1e-5)\n",
    "    deformation = layers.Conv3D(out_channels, kernel_size=3, strides=1,\n",
    "                                padding='same',\n",
    "                                kernel_initializer=kernel_initializer)(x)\n",
    "\n",
    "    nb, nd, nh, nw, nc = tf.shape(deformation)\n",
    "\n",
    "    # Regular grid.\n",
    "    grid = regular_grid_3d(nd, nh, nw)  # shape (D, H, W, 2)\n",
    "    grid = tf.expand_dims(grid, axis=0)  # shape (1, D, H, W, 2)\n",
    "    multiples = tf.stack([nb, 1, 1, 1, 1])\n",
    "    grid = tf.tile(grid, multiples)\n",
    "\n",
    "    # Compute the new sampling grid.\n",
    "    grid_new = grid + deformation\n",
    "    grid_new = tf.clip_by_value(grid_new, -1, 1)\n",
    "\n",
    "    # Sample the moving image using the new sampling grid.\n",
    "    moved = grid_sample_3d(moving, grid_new)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[static, moving],\n",
    "                            outputs=[moved, deformation], name='voxelmorph1')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, moving, static, criterion, optimizer):\n",
    "    nb, nd, nh, nw, nc = tf.keras.backend.int_shape(moving)  # moving.shape\n",
    "\n",
    "    # Repeat the static image along the batch dim.\n",
    "    multiples = tf.constant([nb, 1, 1, 1, 1], tf.int32)\n",
    "    static = tf.tile(static, multiples)\n",
    "\n",
    "    # Define the GradientTape context for automatic differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the deformation field\n",
    "        # inputs = tf.concat([moving, static], axis=-1)\n",
    "        moved, deformation = model({'moving': moving, 'static': static})\n",
    "        # Compute the loss.\n",
    "        # loss = criterion(moved, static)\n",
    "        # loss = criterion(static, moved) + 2*gradient_loss(deformation)\n",
    "        loss = 0.5*criterion(static, moved) + 0.5*criterion(moved, static) + 2*gradient_loss(deformation)\n",
    "    # Compute gradients.\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    # Update the trainable parameters.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(model, moving, static, criterion):\n",
    "    nb, nd, nh, nw, nc = tf.keras.backend.int_shape(moving)  # moving.shape\n",
    "\n",
    "    # Repeat the static image along the batch dim.\n",
    "    multiples = tf.constant([nb, 1, 1, 1, 1], tf.int32)\n",
    "    static = tf.tile(static, multiples)\n",
    "\n",
    "    # Get the deformation field.\n",
    "    # inputs = tf.concat([moving, static], axis=-1)\n",
    "    moved, deformation = model({'moving': moving, 'static': static}, training=False)\n",
    "\n",
    "    # Compute the loss.\n",
    "    # loss = criterion(moved, static)\n",
    "    # loss = criterion(static, moved) + 2*gradient_loss(deformation)\n",
    "    loss = 0.5*criterion(static, moved) + 0.5*criterion(moved, static) + 2*gradient_loss(deformation)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(model, moving, static):\n",
    "    nb, nd, nh, nw, nc = moving.shape\n",
    "\n",
    "    # Repeat the static image along the batch dim.\n",
    "    multiples = tf.constant([nb, 1, 1, 1, 1], tf.int32)\n",
    "    static = tf.tile(static, multiples)\n",
    "\n",
    "    moved, deformation = model({'moving': moving, 'static': static}, training=False)\n",
    "    print(deformation.shape, tf.reduce_max(deformation), tf.reduce_min(deformation), tf.reduce_mean(deformation))\n",
    "\n",
    "    deformation = deformation.numpy()\n",
    "    moved = moved.numpy().squeeze(axis=-1) * 255.0\n",
    "    # moved = moved.astype(np.uint8)[:,:,nh//2,...]\n",
    "    moving = moving.numpy().squeeze(axis=-1) * 255.0\n",
    "    # moving = moving.astype(np.uint8)[:,:,nh//2,...]\n",
    "    static = static.numpy().squeeze(axis=-1) * 255.0\n",
    "    # static = static.astype(np.uint8)[:,:,nh//2,...]\n",
    "\n",
    "\n",
    "    # # Plot images.\n",
    "    # fig = plt.figure(figsize=(3 * 1.7, nb * 1.7))\n",
    "    # titles_list = ['Static', 'Moved', 'Moving']\n",
    "    # images_list = [static, moved, moving]\n",
    "\n",
    "    # moved = moving\n",
    "    dd = []\n",
    "    for i in range(nb):\n",
    "        # for j in range(3):\n",
    "        #     ax = fig.add_subplot(nb, 3, i * 3 + j + 1)\n",
    "        #     if i == 0:\n",
    "        #         ax.set_title(titles_list[j], fontsize=20)\n",
    "        #     ax.set_axis_off()\n",
    "        #     ax.imshow(images_list[j][i], cmap='gray')\n",
    "        regtools.overlay_slices(static[i], moved[i], None, 0,\n",
    "                                \"%d Static\"%i, \"%d Transformed\"%i,\n",
    "                                \"%d_0.png\" % (i))\n",
    "        regtools.overlay_slices(static[i], moved[i], None, 1,\n",
    "                                \"%d Static\"%i, \"%d Transformed\"%i,\n",
    "                                \"%d_1.png\" % (i))\n",
    "        regtools.overlay_slices(static[i], moved[i], None, 2,\n",
    "                                \"%d Static\"%i, \"%d Transformed\"%i,\n",
    "                                \"%d_2.png\" % (i))\n",
    "        d = {'static': static[i].astype(np.uint8), 'moved': moved[i].astype(np.uint8), 'moving': moving[i].astype(np.uint8)}\n",
    "        dd.append(d)\n",
    "    print(moved.min(), moved.max(), static.min(), static.max(), moving.min(), moving.max())\n",
    "    np.save('/content/drive/My Drive/DIPY/T1_T2_new/results_200.npy', dd)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 10 images from dataset\n",
    "T1_dir = HCP_folder + \"/T1/\"\n",
    "\n",
    "T1_files = os.listdir(T1_dir)\n",
    "T1_files.sort()\n",
    "# T1_files = T1_files[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file_list):\n",
    "    images = []\n",
    "    for file in file_list:\n",
    "        image, _ = load_nifti(T1_dir + file)\n",
    "        # image = np.expand_dims(image, axis=-1)\n",
    "        images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = read_dataset(T1_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # brain = np.load('/content/drive/My Drive/DIPY/t1_t2/t1_t2_affine_128.npy')\n",
    "    # static = np.load('/content/drive/My Drive/DIPY/t1_t2/static_128.npy')\n",
    "    dataset = read_dataset(T1_files)\n",
    "    print(\"dataset:\",dataset.shape)\n",
    "    brain = dataset[:50,...]\n",
    "    print(\"brain:\",brain.shape)\n",
    "    static = dataset[50::,...]\n",
    "    print(\"static:\",static.shape)\n",
    "    del dataset\n",
    "    brain = brain.astype(np.float32)/255.0\n",
    "    x_train = brain[:25,...][...,None].copy()\n",
    "    print(\"x_train:\",x_train.shape)\n",
    "    # x_train = x_train.astype(np.float32)/255.0\n",
    "    x_test = brain[25:,...][...,None].copy()\n",
    "    print(\"x_test:\",x_test.shape)\n",
    "    # x_test = x_test.astype(np.float32)/255.0\n",
    "    x_sample = x_test.copy()\n",
    "    # static = brain[-1,...][None,...,None]\n",
    "    static = static[None,...,None]\n",
    "    print(\"static:\",static.shape)\n",
    "    static = static.astype(np.float32)/255.0\n",
    "\n",
    "\n",
    "\n",
    "    min_val = min(static.min(), brain.min())\n",
    "    max_val = max(static.max(), brain.max())\n",
    "    print(min_val, max_val)\n",
    "    bin_centers = np.linspace(min_val, max_val, 32)\n",
    "\n",
    "    del brain\n",
    "\n",
    "\n",
    "    x_train = tf.convert_to_tensor(x_train, dtype='float32')\n",
    "    x_test = tf.convert_to_tensor(x_test, dtype='float32')\n",
    "    x_sample = tf.convert_to_tensor(x_sample, dtype='float32')\n",
    "    static = tf.convert_to_tensor(static, dtype='float32')\n",
    "    # print(x_train.shape, x_test.shape, x_sample.shape, static.shape)\n",
    "\n",
    "    from_tensor_slices = tf.data.Dataset.from_tensor_slices\n",
    "    x_train = from_tensor_slices(x_train).shuffle(10000).batch(args.batch_size)\n",
    "    x_test = from_tensor_slices(x_test).shuffle(10000).batch(args.batch_size)\n",
    "\n",
    "    # S = 128\n",
    "    # # Create a model instance.\n",
    "    # model = voxelmorph1(input_shape=(S, S, S))\n",
    "    model = voxelmorph1(input_shape=(128, 128, 128))\n",
    "\n",
    "    # replace\n",
    "    # model.load_weights('drive/My Drive/DIPY/t1_t2/results/checkpoints/59.h5')\n",
    "    # # or\n",
    "    # tf.keras.models.load_model('name of .h5')\n",
    "\n",
    "\n",
    "    # Select optimizer and loss function.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr)\n",
    "    # criterion = ncc_new\n",
    "    criterion = mutualInformation(bin_centers, sigma_ratio=0.5, max_clip=1, crop_background=False, local_mi=True, patch_size=12)\n",
    "\n",
    "    # Define the metrics to track training and testing losses.\n",
    "    m_train = tf.keras.metrics.Mean(name='loss_train')\n",
    "    m_test = tf.keras.metrics.Mean(name='loss_test')\n",
    "\n",
    "    # Train and evaluate the model.\n",
    "    for epoch in range(args.epochs):\n",
    "        m_train.reset_states()\n",
    "        m_test.reset_states()\n",
    "        for i, moving in enumerate(x_train):\n",
    "            loss_train = train_step(model, moving, static, criterion,\n",
    "                                    optimizer)\n",
    "            m_train.update_state(loss_train)\n",
    "\n",
    "        for i, moving in enumerate(x_test):\n",
    "            loss_test = test_step(model, moving, static, criterion)\n",
    "            m_test.update_state(loss_test)\n",
    "\n",
    "        model.save_weights('data/checkpoints/%d_2.h5'%epoch)\n",
    "        print('Epoch: %3d/%d\\tTrain Loss: %.6f\\tTest Loss: %.6f'\n",
    "              % (epoch + 1, args.epochs, m_train.result(), m_test.result()))\n",
    "    print('\\n')\n",
    "\n",
    "    # Show sample results.\n",
    "    plot_images(model, x_sample, static)\n",
    "\n",
    "    # Save the trained model.\n",
    "    if args.save_model:\n",
    "        model.save_weights('data/results/voxelmorph1-weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: (1065, 128, 128, 128, 1)\n",
      "brain: (50, 128, 128, 128, 1)\n",
      "static: (1015, 128, 128, 128, 1)\n",
      "x_train: (25, 128, 128, 128, 1, 1)\n",
      "x_test: (25, 128, 128, 128, 1, 1)\n",
      "static: (1, 1015, 128, 128, 128, 1, 1)\n",
      "0.0 0.003921569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 16:57:16.350261: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-10 16:57:16.368718: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_141993/1463614979.py\", line 3, in train_step  *\n        nb, nd, nh, nw, nc = tf.keras.backend.int_shape(moving)  # moving.shape\n\n    ValueError: too many values to unpack (expected 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141993/2990954548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_141993/3682560261.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mm_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             loss_train = train_step(model, moving, static, criterion,\n\u001b[0m\u001b[1;32m     71\u001b[0m                                     optimizer)\n\u001b[1;32m     72\u001b[0m             \u001b[0mm_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/__autograph_generated_filedkytwrl4.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(model, moving, static, criterion, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoving\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0mmultiples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mstatic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_141993/1463614979.py\", line 3, in train_step  *\n        nb, nd, nh, nw, nc = tf.keras.backend.int_shape(moving)  # moving.shape\n\n    ValueError: too many values to unpack (expected 5)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    class Args():\n",
    "        batch_size = 1\n",
    "        epochs = 60\n",
    "        lr = 0.001\n",
    "        # label = 1  # which digit images to train on?\n",
    "        # num_samples = 5  # number of sample results to show\n",
    "        save_model = True\n",
    "\n",
    "    args = Args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
